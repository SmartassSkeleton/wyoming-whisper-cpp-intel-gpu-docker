services:
  whisper-cpp:
    build:
      context: .
      args:
        - WHISPER_CPP_VERSION=1.7.4
        # 2025.0.2 seems to have a 50% performance regression
        - BUILD_FROM=intel/oneapi:2025.0.1-0-devel-ubuntu24.04
    container_name: whisper-cpp
    restart: unless-stopped
    # Change user to the one that will run the container
    user: 1000:1000
    group_add:
    # Change this number to match your "render" host group id
    # You can get the id number by running: getent group render
      - "107"
    security_opt:
      - no-new-privileges:true
    ports:
      - 7891:7891
    volumes:
      - type: bind
    # Change to the directory that will store model files
        source: /path/to/models
        target: /models
    devices:
      - /dev/dri:/dev/dri
    environment:
    # Tested to work well on A380, takes ~1 second to process a request after the initial warm-up request
      - BEAM_SIZE=5
      - LANG=en
      - MODEL=large-v2
    # Optional
      - PROMPT=""
      - EXTRA_ARGS=
networks: {}
